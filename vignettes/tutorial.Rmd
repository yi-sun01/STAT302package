---
title: "Project 3: STAT302package Tutorial"
author: "Yi Sun, Yuxin Huang"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{STAT302package Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  fig.width = 6, 
  fig.height = 5, 
  collapse = TRUE,
  comment = "#>"
)
```
## 1. Introduction

This package includes 4 part of functions, which are:\

my_t.test, A function can perform a one sample t test in R.\
my_lm, A function can fit a linear model in R.\
my_knn_cv,A function performs a k-neareast neighbors cross-validation\
my_rf_cv, A function performs a random forest cross-validation\

<br>

To introduce each function of our package, we should first install the sample package:
```{r, eval = FALSE}
devtools::install_github("yi-sun01/STAT302package")
```

And then We load our packages and data we need:

```{r setup}
library(STAT302package)
data("my_penguins")
data("my_gapminder")
set.seed(302)
```

## 2.Tutorial for my_t.test

This function can perform a one sample t test in R. So here, we use the "lifeExp" data from my_gapminder data set to test three different hypothesis about the mean of "lifeExp".
<br>
<br>
In first situation, we set the null hypothesis as: mean of the lifeExp from gapminder data set is equal to 60, and the alternative hypothesis is that the mean of the data set is not equal to 60. We run my_t.test function, put the data, change the alternative parameter as "two.sided" and change the mu as 60 to perform this test and get a list of statistics about this test hypothesis:
```{r}
my_t.test(my_gapminder$lifeExp, "two.sided", 60)
```
From the list, We know the P value for this test is 0.09314, which is greater than our cut off p value 0.05. This comparison indicates that we fail to reject the null hypothesis and the mean of the lifeExp from the gapminder dataset is equal to 60. 
<br>
<br>
In second situation, we set the null hypothesis as: mean of the lifeExp from gapminder data set is equal to 60, and the alternative hypothesis is that the mean of the data set is greater than 60. We run the my_t.test function, put the data, change the alternative parameter as "greater" and change the mu as 60 to perform this test and get a list of statistics about this test hypothesis:
```{r}
my_t.test(my_gapminder$lifeExp, "greater", 60)
```
We have our P value for this test is 0.95343. However, since this is a "greater" hypothesis test. So we need to use 1-0.95343 = 0.04657, this value to compare with the cut off value 0.05. Here is clear that our p value is less than the cut off value, so we reject the null hypothesis and have the evidence to support our alternative hypothesis: the mean of the data set is greater than 60.
<br>
<br>
In third situation, we set the null hypothesis as: mean of the lifeExp from gapminder data set is equal to 60, and the alternative hypothesis is that the mean of the data set is less than 60. We run the my_t.test function, put the data, change the alternative parameter as "less" and change the mu as 60 to perform this test and get a list of statistics about this test hypothesis:
```{r}
my_t.test(my_gapminder$lifeExp, "less", 60)
```
We have our P value for this test is 0.04657, which is less than our cut off p value 0.05. This comparison indicates that we reject the null hypothesis and have the evidence to support our alternative hypothesis: the mean of lifeExp from the gapminder data set is less than 60.
<br>
<br>

## 3.Tutorial for my_lm()

<br>
This function can fit a lieaner model in R. So here, We take the data from gapminder as example. We use "lifeExp" as response variable and "gdpPercap" and "continent" as explanatory variables. 
<br>
<br>
First, we run the function and will get a summary data frame:
```{r}
my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)
```
<br>
Let's take the gdpPercap's estimate as example to explain how to interpret the Estimate statistic in this data frame. First, the Estimate here represents the coefficient for gdpPercap. It means when other covariates are identical, the expected difference in the response between two observations differing by one unit in X is 47.88852.
<br>
<br>
Then we test a hypothesis test for the gadPercap coefficient. The null hypothesis is that the coefficient equals to zero. The alternative hypothesis is that the coefficient doesn't equal to zero. The Pr(>|t|)(which represent p value for the hypothesis test) for the gdpPercap is 2.478202e-98, which is mostly close to 0 and the cut off p value here is 0.05. So the P value for this hypothesis is less than the cut off p value. This comparison indicates that we reject the null hypothesis and have the evidence to support our alternative hypothesis: the coefficient doesn't equal to zero.
<br>
<br>
Finally, let plot the  Actual vs. Fitted values:
```{r, fig.dim = c(6, 5)}
#load the package which we need in order to run ggplot
#use matrix1 to store my_lm data statistics
matrix1 <- my_lm(lifeExp ~ gdpPercap + continent, my_gapminder)

#use real_lm to store lm() data statistics
real_lm <- lm(lifeExp ~ gdpPercap + continent, data = my_gapminder)

#calculate x and use x * estimate to get the actual value
x <- model.matrix(lifeExp ~ gdpPercap + continent, data = my_gapminder)
actual <- x %*% matrix1$Estimate

#use mod_fits to store the fitted value
mod_fits <- fitted(real_lm)
#create a data frame to store the actual value and fitted value
my_df01 <- data.frame(actual = actual , fitted = mod_fits)
#plot the actual vs fitted graph 
#using scatter plot to plot the graph 
graph1 <- ggplot2::ggplot(my_df01, ggplot2::aes(x = fitted, y = actual)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0, col = "red", lty = 2) + 
  ggplot2::theme_bw(base_size = 15) +
  ggplot2::labs(x = "Fitted values", y = "Actual values", 
               title = "Actual vs. Fitted")+
  ggplot2::theme(plot.title = ggplot2::element_text(hjust = 0.5))
graph1
```

From the graph, we can see that the function fit the real data value very well. Since all the points are plotted on the red line.
<br>
<br>
<br>

## 4.Tutorial for my_knn_cv

We will be using "my_penguins" data and the function my_knn_cv() to perform 
k-nearest neighbor cross-validation in this tutorial.
Our goal is to make predictions of the output class species using four covariates 
bill_length_mm, bill_depth_mm, flipper_length_mm, and body_mass_g. For the code chunk
below, we will be using a 5-fold cross validation with k_nn being from 1 to 10.

A k-fold corss-validation is to split data into k groups(folds), use 1 fold as
the training data, use the rest of folds as the test data, and use the test
data to make predictions. Sometimes we would swithc which fold is the test data and
keep repeating the above process until every fold has been the test data.
<br>
```{r}
# filter my_penguins data
# omit NA values
penguins_01 <- na.omit(my_penguins)
# extract "species" from penguins_01 
species_outcome <- dplyr::pull(penguins_01, var = "species")
# only keeps the four covariates we want in the data set :
# bill_length_mm, bill_depth_mm, flipper_length_mm, and body_mass_g
penguins_01 <- dplyr::select(penguins_01, 3:6)

# initialize a vector to store CV miss-classification rate
cv_err <- base::rep(NA, 10)

# initialize a vector to store training miss-classification rate
train_err <- base::rep(NA, 10)
  
for (i in 1:10) {
  # compute and store the CV error
  result <- STAT302package::my_knn_cv(penguins_01, species_outcome, i, 5)
  cv_err[i] <- result[["cv_error"]]
  # compute and store the training error
  train_err[i] <- mean(result[["class"]] != species_outcome)
}

# create a data frame in order to make a table
knn_value <- c(1:10)
my_df <- data.frame(knn_value, train_err, cv_err)
#rownames(my_df) <- c("1-nearest neighbor", "5_nearest neighbors")
colnames(my_df) <- c("k_nn", "training error", "CV error")

# create the table with styling
kableExtra::kable_styling(knitr::kable(my_df))
  
```

<br>

Based on training missclassification rates, I would chosee k_nn = 1 because it has the
smallest training missclassification rate. Based on CV missclassification rates, I would choose
k_nn = 1 as well because it has the smallest missclassification rate. In practice, I would
choose the model with k_nn = 1 because it has both the smallest training missclassification rate and
the smallest CV missclassification rate.

<br>

## 5.Tutorial for my_rf_cv


We will be using the function my_rf_cv to perform random forest cross-validation
in this tutorial. Our goal is to make predictions of body_mass_g using covariates bill_length_mm, bill_depth_mm, and flipper_length_mm. We choose three values for k: 2, 5, 10. For each
value of k, we will perform the random forest cross-validation 30 times and keep track
of the CV estimated MSE for each iteration.
<br>
```{r, fig.show = "hold"}
# the values of k
k_value <- c(2, 5, 10)

# create a list in advance, to keep track of the CV MSE
output_rf_cv <- list()

for (i in 1:length(k_value)) {
  # keep track of MSE for each iteration of the total 30 iterations
  MSE <- c(1:30)
  
  for (j in 1:30) {
    
    # use my_rf_cv to calculate the MSE
    MSE[j] <- STAT302package::my_rf_cv(k_value[i])
    
  }
  
  # store the MSE in the list
  output_rf_cv[[i]] <- MSE
 
}

# a vector of the average CV estimates for each k
mean_MSE <- c(mean(output_rf_cv[[1]]), mean(output_rf_cv[[2]]), mean(output_rf_cv[[3]]))
# a vector of the standard deviation of the CV estimates across k                  
sd_MSE <- c(sd(output_rf_cv[[1]]), sd(output_rf_cv[[2]]), sd(output_rf_cv[[3]]))
                                       
# create a data frame in order to build a table
my_df_rf <- data.frame(mean_MSE, sd_MSE)
rownames(my_df_rf) <- c("k = 2", "k = 5", "k = 10")
colnames(my_df_rf) <- c("mean of MSE", "standard deviation")

# create a table as the final output
kableExtra::kable_styling(knitr::kable(my_df_rf))

```

<br>

From the tabe above, we can see that both the means of CV MSE and the standard deviations of CV MSE
decrease as the value of k increases. This is because when the value of k increases, our predictions get 
more accurate and the test errors decreases. Therefore, CV MSE minimized at k = 10.

<br>

```{r, fig.show = "hold"}

# create a vector representing the 30 iterations
iteration <-  cut(c(1:30), breaks = c(0, 10, 20, 30), 
                    labels = c("0-10", "10-20", "20-30"))

# create a data frame in order to make a box-plot of k = 2
graph1_data <- data.frame(output_rf_cv[[1]], iteration)
colnames(graph1_data) <- c("MSE", "iteration")
# plot the "MSE vs. Iterations" graph for k = 2
ggplot2::ggplot(data = graph1_data, 
       ggplot2::aes(x = iteration, y = MSE, group = iteration)) +
  
    ggplot2::geom_boxplot(size = 1, color = "cornflowerblue" ) +
    
    # set up the title of the graph
    # lable the two axes
    ggplot2::labs(title = "Estemiated CV MSE when k = 2",
         x = "Number of Iterations", y = "MSE") +
    
    # change background color to black and white
    ggplot2::theme_bw(base_size = 20) +
  
    # adjusting the size of the main title and its position
    # adjust the size of titles of axes
    ggplot2::theme(plot.title = ggplot2::element_text(size=20, hjust = 0.5), 
          axis.title.x = ggplot2::element_text(size = 18),
          axis.title.y = ggplot2::element_text(size = 18))



# create a data frame in order to make a box-plot of k = 5
graph2_data <- data.frame(output_rf_cv[[2]], iteration)
colnames(graph2_data) <- c("MSE", "iteration")
# plot the "MSE vs. Iterations" graph for k = 5
ggplot2::ggplot(data = graph2_data, 
       ggplot2::aes(x = iteration, y = MSE, group = iteration)) +
  
    ggplot2::geom_boxplot(size = 1, color = "cornflowerblue" ) +
    
    # set up the title of the graph
    # lable the two axes
    ggplot2::labs(title = "Estemiated CV MSE when k = 5",
         x = "Number of Iterations", y = "MSE") +
    
    # change background color to black and white
    ggplot2::theme_bw(base_size = 20) +
  
    # adjusting the size of the main title and its position
    # adjust the size of titles of axes
    ggplot2::theme(plot.title = ggplot2::element_text(size=20, hjust = 0.5), 
          axis.title.x = ggplot2::element_text(size = 18),
          axis.title.y = ggplot2::element_text(size = 18))



# create a data frame in order to make a box-plot of k = 10
graph3_data <- data.frame(output_rf_cv[[3]], iteration)
colnames(graph3_data) <- c("MSE", "iteration")
# plot the "MSE vs. Iterations" graph for k = 5
ggplot2::ggplot(data = graph3_data, 
       ggplot2::aes(x = iteration, y = MSE, group = iteration)) +
  
    ggplot2::geom_boxplot(size = 1, color = "cornflowerblue" ) +
    
    # set up the title of the graph
    # lable the two axes
    ggplot2::labs(title = "Estemiated CV MSE when k = 10",
         x = "Number of Iterations", y = "MSE") +
    
    # change background color to black and white
    ggplot2::theme_bw(base_size = 20) +
  
    # adjusting the size of the main title and its position
    # adjust the size of titles of axes
    ggplot2::theme(plot.title = ggplot2::element_text(size=20, hjust = 0.5), 
          axis.title.x = ggplot2::element_text(size = 18),
          axis.title.y = ggplot2::element_text(size = 18))

```
<br>
<br>

The above three boxplots show the CV estimated MSE of 30 iterations for k = 2, 5, 10.
We can see that k = 2 has the highst MSE and medians of MSE, and the MSE of k = 10 are 
relatively lower. Therefore, CV MSE decreases as the value of k increases and CV MSE is 
minimized at k = 10.

<br>
